{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Twitter Data for Cities that Have NOT Declared a Climate Emergency #\n",
    "\n",
    "This notebook focuses on getting Twitter data (all tweets) from the 10 largest cities (population-wise) that have declared a climate emergency. \n",
    "\n",
    "  \n",
    "\n",
    "This first portion of the notebook is dedicated to printing an output that we'll use for a library called \"Twitterscraper.\" This package uses CL for data collection. We'll load in the data back into this notebook. \n",
    "\n",
    "https://github.com/taspinar/twitterscraper\n",
    "    \n",
    "Once the data from twitterscraper is loaded, for the last portion, we'll then merge all of the cities' data into one large dataset for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import json      # library for working with JSON-formatted text strings\n",
    "import pprint as pp    # library for cleanly printing Python data structures\n",
    "import seaborn as sns\n",
    "import twitterscraper as ts\n",
    "from twitterscraper import query_tweets #library downloaded\n",
    "import os as os\n",
    "\n",
    "import subprocess #this enables us to pass CL code directly from Jupyter Notebooks \n",
    "from subprocess import Popen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Twitterscraper Command ## \n",
    "\n",
    "The code below scrapes Twitter accounts from each city, scrapes *all* of their tweets, and makes one big JSON file. Rather than pasting the command into the CL, this function uses \"subprocess\" (a standard library already with Python) to pass the command directly through Jupyter Notebooks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(json_files):\n",
    "    data_frames = []\n",
    "    \n",
    "    for file in json_files:\n",
    "        print (file)\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        d = {'username': [x['username'] for x in data],\n",
    "        'time': [x['timestamp'] for x in data],\n",
    "        'tweet': [x['text'] for x in data],\n",
    "        'likes': [x['likes'] for x in data],\n",
    "        'replies': [x['replies'] for x in data],\n",
    "        'user_ID' : [x['screen_name'] for x in data]}\n",
    "    \n",
    "        data_frames.append(pd.DataFrame.from_dict(d))\n",
    "    return data_frames\n",
    "\n",
    "def combine_data(data_frames): #this will allow us to merge dataframes \"*\" allows us to pass X dataframes\n",
    "    return pd.concat(data_frames)\n",
    "\n",
    "\n",
    "def buildQuery(accounts):\n",
    "    scraper_query = ''\n",
    "    \n",
    "    #this builds our search query\n",
    "    for index, each_account in enumerate (accounts):\n",
    "        next_index = index + 1 #this is so that we don't have an extra \"OR\" at the end, it \"knows\" the last thing\n",
    "        if next_index > len(accounts) - 1: \n",
    "            scraper_query = scraper_query + \"from:\"+ each_account\n",
    "        else:\n",
    "            scraper_query = scraper_query + \"from:\"+ each_account + \" OR \"\n",
    "            \n",
    "    return scraper_query\n",
    "\n",
    "def launch(command, output):\n",
    "    print (command)\n",
    "    \n",
    "    outputFile = open(output, 'w+')\n",
    "    p = Popen(command, stdout=outputFile, stderr=outputFile, universal_newlines=True)\n",
    "    output, errors = p.communicate()\n",
    "    #p.wait() # Wait for sub process to finish before moving on to make frame \n",
    "\n",
    "    #TCB - having issues with my erros,trying to ex that out\n",
    "    if errors:\n",
    "        print (errors)\n",
    "    outputFile.close()\n",
    "            \n",
    "def scrape(accounts):\n",
    "    data_files = []\n",
    "    \n",
    "    for user in accounts:\n",
    "        path_to_output_file = user + \".txt\" #we'll get both txt and json, but just ignore txt\n",
    "        path_to_data_file = user + \".JSON\"\n",
    "        data_files.append(path_to_data_file)\n",
    "        \n",
    "        query = 'from: ' + user\n",
    "        command = [\"twitterscraper\", query, \n",
    "                   \"--lang\", \"en\", \"--all\", \"-ow\", \"-p\", \"40\", \"-o\", path_to_data_file]\n",
    "        launch(command, path_to_output_file)\n",
    " \n",
    "    return data_files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I created a list of all the accounts I wish to scrape (I broke it up into 3 \"searches\" because this process is extremely time-consuming). However, using \"scrape()\" you can input all the accounts, it'll just an hour or so to get all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "phila_accounts = [\"PhiladelphiaGov\", \"GreenworksPhila\", \"PhillyOTIS\", \"PhilaParkandRec\", \"PhilaHsgAuthPHA\", \"PHLPlanDevelop\", \"PhilaOEM\", \"SEPTA\"] #add accounts to scrape here\n",
    "houston_accounts = [\"HPARD\",\"HoustonHCDD\", \"HoustonPlanning\", \"HoustonOEM\", \"HouPublicWorks\", \"HoustonTX\", \"GreenHoustonTx\", \"METROHouston\", \"HoustonOEM\"] #add accounts to scrape here\n",
    "phx_accounts = [\"CityofPhoenixAZ\", \"phxenvironment\" , \"StreetsPHX\", \"PhoenixParks\", \"PhoenixParks\", \"PHXPlanandDev\", \"ResilientPHX\", \"TalkingTrashPHX\", \"PhoenixMetroBus\"] #add accounts to scrape here\n",
    "\n",
    "#2\n",
    "sanantonio_accounts = [\"COSAGOV\", \"COSAsustainable\", \"SAParksandRec\", \"SATomorrow2040\", \"SanAntonioOEM\"]\n",
    "dallas_accounts = [\"CityOfDallas\", \"DallasClimate\", \"DallasParkRec\", \"DallasPlanUD\", \"DallasOEM\", \"dartmedia\", \"dallaszerowaste\"] \n",
    "jax_accounts = [\"CityofJax\", \"JaxReady\", \"JTAFLA\"] \n",
    "\n",
    "#3\n",
    "ftworth_accounts = [\"CityofFortWorth\", \"FortWorthParks\", \"FWOEM\", \"TrinityMetro\", \"TarrantCountyTX\"] \n",
    "charlotte_accounts = [\"CLTgov\", \"CLTSustainable\", \"CharlotteDOT\", \"HNScharlotte\", \"CharMeckEM\", \"CATSRideTransit\", \"CLTWater\"] \n",
    "columbus_accounts = [\"ColumbusGov\", \"SustainableCol1\", \"CbusMetroParks\", \"ColumbusDP\", \"COTABus\"] \n",
    "indianapolis_accounts = [\"Indy_CIO\", \"SustainIndy\", \"IndyParksandRec\", \"IndyDPW\", \"IndyGoBus\", \"IndyDMD\", \"Indy_CIO\", \"IndyDBNS\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitterscraper', 'from: PhiladelphiaGov', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhiladelphiaGov.JSON']\n",
      "['twitterscraper', 'from: GreenworksPhila', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'GreenworksPhila.JSON']\n",
      "['twitterscraper', 'from: PhillyOTIS', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhillyOTIS.JSON']\n",
      "['twitterscraper', 'from: PhilaParkandRec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhilaParkandRec.JSON']\n",
      "['twitterscraper', 'from: PhilaHsgAuthPHA', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhilaHsgAuthPHA.JSON']\n",
      "['twitterscraper', 'from: PHLPlanDevelop', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PHLPlanDevelop.JSON']\n",
      "['twitterscraper', 'from: PhilaOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhilaOEM.JSON']\n",
      "['twitterscraper', 'from: SEPTA', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SEPTA.JSON']\n",
      "['twitterscraper', 'from: HPARD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HPARD.JSON']\n",
      "['twitterscraper', 'from: HoustonHCDD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonHCDD.JSON']\n",
      "['twitterscraper', 'from: HoustonPlanning', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonPlanning.JSON']\n",
      "['twitterscraper', 'from: HoustonOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonOEM.JSON']\n",
      "['twitterscraper', 'from: HouPublicWorks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HouPublicWorks.JSON']\n",
      "['twitterscraper', 'from: HoustonTX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonTX.JSON']\n",
      "['twitterscraper', 'from: GreenHoustonTx', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'GreenHoustonTx.JSON']\n",
      "['twitterscraper', 'from: METROHouston', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'METROHouston.JSON']\n",
      "['twitterscraper', 'from: HoustonOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonOEM.JSON']\n",
      "['twitterscraper', 'from: CityofPhoenixAZ', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityofPhoenixAZ.JSON']\n",
      "['twitterscraper', 'from: phxenvironment', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'phxenvironment.JSON']\n",
      "['twitterscraper', 'from: StreetsPHX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'StreetsPHX.JSON']\n",
      "['twitterscraper', 'from: PhoenixParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhoenixParks.JSON']\n",
      "['twitterscraper', 'from: PhoenixParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhoenixParks.JSON']\n",
      "['twitterscraper', 'from: PHXPlanandDev', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PHXPlanandDev.JSON']\n",
      "['twitterscraper', 'from: ResilientPHX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ResilientPHX.JSON']\n",
      "['twitterscraper', 'from: TalkingTrashPHX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'TalkingTrashPHX.JSON']\n",
      "['twitterscraper', 'from: PhoenixMetroBus', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhoenixMetroBus.JSON']\n",
      "['twitterscraper', 'from: COSAGOV', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'COSAGOV.JSON']\n",
      "['twitterscraper', 'from: COSAsustainable', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'COSAsustainable.JSON']\n",
      "['twitterscraper', 'from: SAParksandRec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SAParksandRec.JSON']\n",
      "['twitterscraper', 'from: SATomorrow2040', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SATomorrow2040.JSON']\n",
      "['twitterscraper', 'from: SanAntonioOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SanAntonioOEM.JSON']\n",
      "['twitterscraper', 'from: CityOfDallas', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityOfDallas.JSON']\n",
      "['twitterscraper', 'from: DallasClimate', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DallasClimate.JSON']\n",
      "['twitterscraper', 'from: DallasParkRec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DallasParkRec.JSON']\n",
      "['twitterscraper', 'from: DallasPlanUD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DallasPlanUD.JSON']\n",
      "['twitterscraper', 'from: DallasOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DallasOEM.JSON']\n",
      "['twitterscraper', 'from: dartmedia', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'dartmedia.JSON']\n",
      "['twitterscraper', 'from: dallaszerowaste', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'dallaszerowaste.JSON']\n",
      "['twitterscraper', 'from: CityofJax', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityofJax.JSON']\n",
      "['twitterscraper', 'from: JaxReady', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'JaxReady.JSON']\n",
      "['twitterscraper', 'from: JTAFLA', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'JTAFLA.JSON']\n",
      "['twitterscraper', 'from: CityofFortWorth', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityofFortWorth.JSON']\n",
      "['twitterscraper', 'from: FortWorthParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'FortWorthParks.JSON']\n",
      "['twitterscraper', 'from: FWOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'FWOEM.JSON']\n",
      "['twitterscraper', 'from: TrinityMetro', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'TrinityMetro.JSON']\n",
      "['twitterscraper', 'from: TarrantCountyTX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'TarrantCountyTX.JSON']\n",
      "['twitterscraper', 'from: CLTgov', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CLTgov.JSON']\n",
      "['twitterscraper', 'from: CLTSustainable', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CLTSustainable.JSON']\n",
      "['twitterscraper', 'from: CharlotteDOT', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CharlotteDOT.JSON']\n",
      "['twitterscraper', 'from: HNScharlotte', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HNScharlotte.JSON']\n",
      "['twitterscraper', 'from: CharMeckEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CharMeckEM.JSON']\n",
      "['twitterscraper', 'from: CATSRideTransit', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CATSRideTransit.JSON']\n",
      "['twitterscraper', 'from: CLTWater', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CLTWater.JSON']\n",
      "['twitterscraper', 'from: ColumbusGov', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ColumbusGov.JSON']\n",
      "['twitterscraper', 'from: SustainableCol1', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SustainableCol1.JSON']\n",
      "['twitterscraper', 'from: CbusMetroParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CbusMetroParks.JSON']\n",
      "['twitterscraper', 'from: COTABus', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'COTABus.JSON']\n",
      "['twitterscraper', 'from: Indy_CIO', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'Indy_CIO.JSON']\n",
      "['twitterscraper', 'from: SustainIndy', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SustainIndy.JSON']\n",
      "['twitterscraper', 'from: IndyParksandRec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyParksandRec.JSON']\n",
      "['twitterscraper', 'from: IndyDPW', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyDPW.JSON']\n",
      "['twitterscraper', 'from: IndyGoBus', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyGoBus.JSON']\n",
      "['twitterscraper', 'from: IndyDMD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyDMD.JSON']\n",
      "['twitterscraper', 'from: Indy_CIO', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'Indy_CIO.JSON']\n",
      "['twitterscraper', 'from: IndyDBNS', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyDBNS.JSON']\n"
     ]
    }
   ],
   "source": [
    "# one big file\n",
    "\n",
    "nonclimate_accounts = [\"PhiladelphiaGov\", \"GreenworksPhila\", \"PhillyOTIS\", \"PhilaParkandRec\", \"PhilaHsgAuthPHA\", \n",
    "                       \"PHLPlanDevelop\", \"PhilaOEM\", \"SEPTA\", \"HPARD\",\"HoustonHCDD\", \"HoustonPlanning\", \"HoustonOEM\", \n",
    "                       \"HouPublicWorks\", \"HoustonTX\", \"GreenHoustonTx\", \"METROHouston\", \"HoustonOEM\", \"CityofPhoenixAZ\", \n",
    "                       \"phxenvironment\" , \"StreetsPHX\", \"PhoenixParks\", \"PhoenixParks\", \"PHXPlanandDev\", \"ResilientPHX\", \n",
    "                       \"TalkingTrashPHX\", \"PhoenixMetroBus\", \"COSAGOV\", \"COSAsustainable\", \"SAParksandRec\", \"SATomorrow2040\", \n",
    "                       \"SanAntonioOEM\", \"CityOfDallas\", \"DallasClimate\", \"DallasParkRec\", \"DallasPlanUD\", \"DallasOEM\", \n",
    "                       \"dartmedia\", \"dallaszerowaste\", \"CityofJax\", \"JaxReady\", \"JTAFLA\", \"CityofFortWorth\", \"FortWorthParks\", \n",
    "                       \"FWOEM\", \"TrinityMetro\", \"TarrantCountyTX\", \"CLTgov\", \"CLTSustainable\", \"CharlotteDOT\", \"HNScharlotte\", \n",
    "                       \"CharMeckEM\", \"CATSRideTransit\", \"CLTWater\", \"ColumbusGov\", \"SustainableCol1\", \"CbusMetroParks\", \n",
    "                       \"COTABus\", \"Indy_CIO\", \"SustainIndy\", \"IndyParksandRec\", \"IndyDPW\", \"IndyGoBus\", \"IndyDMD\", \"Indy_CIO\", \n",
    "                       \"IndyDBNS\"] \n",
    " \n",
    " \n",
    "                             \n",
    "\n",
    "nonclimate_output = scrape(nonclimate_accounts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitterscraper', 'from: PhiladelphiaGov', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhiladelphiaGov.JSON']\n",
      "['twitterscraper', 'from: GreenworksPhila', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'GreenworksPhila.JSON']\n",
      "['twitterscraper', 'from: PhillyOTIS', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhillyOTIS.JSON']\n",
      "['twitterscraper', 'from: PhilaParkandRec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhilaParkandRec.JSON']\n",
      "['twitterscraper', 'from: PhilaHsgAuthPHA', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhilaHsgAuthPHA.JSON']\n",
      "['twitterscraper', 'from: PHLPlanDevelop', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PHLPlanDevelop.JSON']\n",
      "['twitterscraper', 'from: PhilaOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhilaOEM.JSON']\n",
      "['twitterscraper', 'from: SEPTA', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SEPTA.JSON']\n",
      "['twitterscraper', 'from: HPARD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HPARD.JSON']\n",
      "['twitterscraper', 'from: HoustonHCDD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonHCDD.JSON']\n",
      "['twitterscraper', 'from: HoustonPlanning', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonPlanning.JSON']\n",
      "['twitterscraper', 'from: HoustonOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonOEM.JSON']\n",
      "['twitterscraper', 'from: HouPublicWorks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HouPublicWorks.JSON']\n",
      "['twitterscraper', 'from: HoustonTX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonTX.JSON']\n",
      "['twitterscraper', 'from: GreenHoustonTx', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'GreenHoustonTx.JSON']\n",
      "['twitterscraper', 'from: METROHouston', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'METROHouston.JSON']\n",
      "['twitterscraper', 'from: HoustonOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HoustonOEM.JSON']\n",
      "['twitterscraper', 'from: CityofPhoenixAZ', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityofPhoenixAZ.JSON']\n",
      "['twitterscraper', 'from: phxenvironment', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'phxenvironment.JSON']\n",
      "['twitterscraper', 'from: StreetsPHX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'StreetsPHX.JSON']\n",
      "['twitterscraper', 'from: PhoenixParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhoenixParks.JSON']\n",
      "['twitterscraper', 'from: PhoenixParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhoenixParks.JSON']\n",
      "['twitterscraper', 'from: PHXPlanandDev', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PHXPlanandDev.JSON']\n",
      "['twitterscraper', 'from: ResilientPHX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ResilientPHX.JSON']\n",
      "['twitterscraper', 'from: TalkingTrashPHX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'TalkingTrashPHX.JSON']\n",
      "['twitterscraper', 'from: PhoenixMetroBus', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'PhoenixMetroBus.JSON']\n"
     ]
    }
   ],
   "source": [
    "# broken into 3 groups\n",
    "\n",
    "nonclimate_accounts1 = [\"PhiladelphiaGov\", \"GreenworksPhila\", \"PhillyOTIS\", \"PhilaParkandRec\", \"PhilaHsgAuthPHA\", \"PHLPlanDevelop\", \"PhilaOEM\", \"SEPTA\", \"HPARD\",\"HoustonHCDD\", \"HoustonPlanning\", \"HoustonOEM\", \"HouPublicWorks\", \"HoustonTX\", \"GreenHoustonTx\", \"METROHouston\", \"HoustonOEM\", \"CityofPhoenixAZ\", \"phxenvironment\" , \"StreetsPHX\", \"PhoenixParks\", \"PhoenixParks\", \"PHXPlanandDev\", \"ResilientPHX\", \"TalkingTrashPHX\", \"PhoenixMetroBus\"] \n",
    "                             \n",
    "\n",
    "nonclimate1_output = scrape(nonclimate_accounts1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitterscraper', 'from: COSAGOV', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'COSAGOV.JSON']\n",
      "['twitterscraper', 'from: COSAsustainable', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'COSAsustainable.JSON']\n",
      "['twitterscraper', 'from: SAParksandRec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SAParksandRec.JSON']\n",
      "['twitterscraper', 'from: SATomorrow2040', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SATomorrow2040.JSON']\n",
      "['twitterscraper', 'from: SanAntonioOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SanAntonioOEM.JSON']\n",
      "['twitterscraper', 'from: CityOfDallas', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityOfDallas.JSON']\n",
      "['twitterscraper', 'from: DallasClimate', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DallasClimate.JSON']\n",
      "['twitterscraper', 'from: DallasParkRec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DallasParkRec.JSON']\n",
      "['twitterscraper', 'from: DallasPlanUD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DallasPlanUD.JSON']\n",
      "['twitterscraper', 'from: DallasOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DallasOEM.JSON']\n",
      "['twitterscraper', 'from: dartmedia', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'dartmedia.JSON']\n",
      "['twitterscraper', 'from: dallaszerowaste', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'dallaszerowaste.JSON']\n",
      "['twitterscraper', 'from: CityofJax', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityofJax.JSON']\n",
      "['twitterscraper', 'from: JaxReady', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'JaxReady.JSON']\n",
      "['twitterscraper', 'from: JTAFLA', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'JTAFLA.JSON']\n"
     ]
    }
   ],
   "source": [
    "nonclimate_accounts_2 = [\"COSAGOV\", \"COSAsustainable\", \"SAParksandRec\", \"SATomorrow2040\", \"SanAntonioOEM\", \"CityOfDallas\", \"DallasClimate\", \"DallasParkRec\", \"DallasPlanUD\", \"DallasOEM\", \"dartmedia\", \"dallaszerowaste\", \"CityofJax\", \"JaxReady\", \"JTAFLA\"] \n",
    "\n",
    "climate_emergency_output_2 = scrape(nonclimate_accounts_2)\n",
    "nonclimate_output_2 = climate_emergency_output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitterscraper', 'from: CityofFortWorth', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityofFortWorth.JSON']\n",
      "['twitterscraper', 'from: FortWorthParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'FortWorthParks.JSON']\n",
      "['twitterscraper', 'from: FWOEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'FWOEM.JSON']\n",
      "['twitterscraper', 'from: TrinityMetro', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'TrinityMetro.JSON']\n",
      "['twitterscraper', 'from: TarrantCountyTX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'TarrantCountyTX.JSON']\n",
      "['twitterscraper', 'from: CLTgov', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CLTgov.JSON']\n",
      "['twitterscraper', 'from: CLTSustainable', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CLTSustainable.JSON']\n",
      "['twitterscraper', 'from: CharlotteDOT', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CharlotteDOT.JSON']\n",
      "['twitterscraper', 'from: HNScharlotte', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HNScharlotte.JSON']\n",
      "['twitterscraper', 'from: CharMeckEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CharMeckEM.JSON']\n",
      "['twitterscraper', 'from: CATSRideTransit', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CATSRideTransit.JSON']\n",
      "['twitterscraper', 'from: CLTWater', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CLTWater.JSON']\n",
      "['twitterscraper', 'from: ColumbusGov', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ColumbusGov.JSON']\n",
      "['twitterscraper', 'from: SustainableCol1', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SustainableCol1.JSON']\n",
      "['twitterscraper', 'from: CbusMetroParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CbusMetroParks.JSON']\n",
      "['twitterscraper', 'from: COTABus', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'COTABus.JSON']\n",
      "['twitterscraper', 'from: Indy_CIO', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'Indy_CIO.JSON']\n",
      "['twitterscraper', 'from: SustainIndy', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SustainIndy.JSON']\n",
      "['twitterscraper', 'from: IndyParksandRec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyParksandRec.JSON']\n",
      "['twitterscraper', 'from: IndyDPW', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyDPW.JSON']\n",
      "['twitterscraper', 'from: IndyGoBus', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyGoBus.JSON']\n",
      "['twitterscraper', 'from: IndyDMD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyDMD.JSON']\n",
      "['twitterscraper', 'from: Indy_CIO', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'Indy_CIO.JSON']\n",
      "['twitterscraper', 'from: IndyDBNS', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'IndyDBNS.JSON']\n"
     ]
    }
   ],
   "source": [
    "nonclimate_accounts_3 = [\"CityofFortWorth\", \"FortWorthParks\", \"FWOEM\", \"TrinityMetro\", \"TarrantCountyTX\", \"CLTgov\", \"CLTSustainable\", \"CharlotteDOT\", \"HNScharlotte\", \"CharMeckEM\", \"CATSRideTransit\", \"CLTWater\", \"ColumbusGov\", \"SustainableCol1\", \"CbusMetroParks\", \"COTABus\", \"Indy_CIO\", \"SustainIndy\", \"IndyParksandRec\", \"IndyDPW\", \"IndyGoBus\", \"IndyDMD\", \"Indy_CIO\", \"IndyDBNS\"] \n",
    "\n",
    "\n",
    "nonclimate_output_3 = scrape(nonclimate_accounts_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SeattleOPCD.JSON', 'CityofSeattle.JSON', 'seattledot.JSON', 'SeattleOSE.JSON', 'kcmetrobus.JSON', 'LACity.JSON', 'LADOTofficial.JSON', 'lacountyparks.JSON', 'HCIDLA.JSON', 'Planning4LA.JSON', 'metrolosangeles.JSON', 'PortofLA.JSON', 'NYC_DOT.JSON', 'NYCParks.JSON', 'NYCHA.JSON', 'NYCPlanning.JSON', 'nycemergencymgt.JSON', 'MTA.JSON']\n"
     ]
    }
   ],
   "source": [
    "#ignore the below, my original function didn't return a list with .JSON - and I didn't want to re-run the scraping process. \n",
    "\n",
    "climate_emergency_accounts = [\"SeattleOPCD\", \"CityofSeattle\", \"seattledot\", \"SeattleOSE\", \"kcmetrobus\", \n",
    "                             \"LACity\", \"LADOTofficial\", \"lacountyparks\", \"HCIDLA\", \"Planning4LA\", \"metrolosangeles\", \"PortofLA\", \n",
    "                             \"NYC_DOT\", \"NYCParks\", \"NYCHA\", \"NYCPlanning\", \"nycemergencymgt\", \"MTA\"]\n",
    "\n",
    "climate_emergency_output_1 = []\n",
    "for account in climate_emergency_accounts:\n",
    "    climate_emergency_output_1.append(account + \".JSON\")\n",
    "    \n",
    "print (climate_emergency_output_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting JSONs to DataFrames ##\n",
    "\n",
    "json_to_df() takes the json list output above and converts all the data into a list of dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhiladelphiaGov.JSON\n",
      "GreenworksPhila.JSON\n",
      "PhillyOTIS.JSON\n",
      "PhilaParkandRec.JSON\n",
      "PhilaHsgAuthPHA.JSON\n",
      "PHLPlanDevelop.JSON\n",
      "PhilaOEM.JSON\n",
      "SEPTA.JSON\n",
      "HPARD.JSON\n",
      "HoustonHCDD.JSON\n",
      "HoustonPlanning.JSON\n",
      "HoustonOEM.JSON\n",
      "HouPublicWorks.JSON\n",
      "HoustonTX.JSON\n",
      "GreenHoustonTx.JSON\n",
      "METROHouston.JSON\n",
      "HoustonOEM.JSON\n",
      "CityofPhoenixAZ.JSON\n",
      "phxenvironment.JSON\n",
      "StreetsPHX.JSON\n",
      "PhoenixParks.JSON\n",
      "PhoenixParks.JSON\n",
      "PHXPlanandDev.JSON\n",
      "ResilientPHX.JSON\n",
      "TalkingTrashPHX.JSON\n",
      "PhoenixMetroBus.JSON\n",
      "COSAGOV.JSON\n",
      "COSAsustainable.JSON\n",
      "SAParksandRec.JSON\n",
      "SATomorrow2040.JSON\n",
      "SanAntonioOEM.JSON\n",
      "CityOfDallas.JSON\n",
      "DallasClimate.JSON\n",
      "DallasParkRec.JSON\n",
      "DallasPlanUD.JSON\n",
      "DallasOEM.JSON\n",
      "dartmedia.JSON\n",
      "dallaszerowaste.JSON\n",
      "CityofJax.JSON\n",
      "JaxReady.JSON\n",
      "JTAFLA.JSON\n",
      "CityofFortWorth.JSON\n",
      "FortWorthParks.JSON\n",
      "FWOEM.JSON\n",
      "TrinityMetro.JSON\n",
      "TarrantCountyTX.JSON\n",
      "CLTgov.JSON\n",
      "CLTSustainable.JSON\n",
      "CharlotteDOT.JSON\n",
      "HNScharlotte.JSON\n",
      "CharMeckEM.JSON\n",
      "CATSRideTransit.JSON\n",
      "CLTWater.JSON\n",
      "ColumbusGov.JSON\n",
      "SustainableCol1.JSON\n",
      "CbusMetroParks.JSON\n",
      "COTABus.JSON\n",
      "Indy_CIO.JSON\n",
      "SustainIndy.JSON\n",
      "IndyParksandRec.JSON\n",
      "IndyDPW.JSON\n",
      "IndyGoBus.JSON\n",
      "IndyDMD.JSON\n",
      "Indy_CIO.JSON\n",
      "IndyDBNS.JSON\n"
     ]
    }
   ],
   "source": [
    "dataframe_1 = json_to_df(nonclimate1_output)\n",
    "\n",
    "dataframe_2 = json_to_df(nonclimate_output_2)\n",
    "\n",
    "dataframe_3 = json_to_df(nonclimate_output_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = combine_data(dataframe_1)\n",
    "merge2 = combine_data(dataframe_2)\n",
    "merge3 = combine_data(dataframe_3)\n",
    "\n",
    "frames = [merge1, merge2, merge3]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "result\n",
    "\n",
    "to_keep = [\"PhiladelphiaGov\", \"GreenworksPhila\", \"PhillyOTIS\", \"PhilaParkandRec\", \"PhilaHsgAuthPHA\", \"PHLPlanDevelop\", \n",
    "           \"PhilaOEM\", \"SEPTA\", \"HPARD\",\"HoustonHCDD\", \"HoustonPlanning\", \"HoustonOEM\", \"HouPublicWorks\", \"HoustonTX\", \n",
    "           \"GreenHoustonTx\", \"METROHouston\", \"HoustonOEM\", \"CityofPhoenixAZ\", \"phxenvironment\" , \"StreetsPHX\", \"PhoenixParks\", \n",
    "           \"PhoenixParks\", \"PHXPlanandDev\", \"ResilientPHX\", \"TalkingTrashPHX\", \"PhoenixMetroBus\", \"COSAGOV\", \"COSAsustainable\",\n",
    "           \"SAParksandRec\", \"SATomorrow2040\", \"SanAntonioOEM\", \"CityOfDallas\", \"DallasClimate\", \"DallasParkRec\", \"DallasPlanUD\", \n",
    "           \"DallasOEM\", \"dartmedia\", \"dallaszerowaste\", \"CityofJax\", \"JaxReady\", \"JTAFLA\", \"CityofFortWorth\", \"FortWorthParks\", \n",
    "           \"FWOEM\", \"TrinityMetro\", \"TarrantCountyTX\", \"CLTgov\", \"CLTSustainable\", \"CharlotteDOT\", \"HNScharlotte\", \"CharMeckEM\", \n",
    "           \"CATSRideTransit\", \"CLTWater\", \"ColumbusGov\", \"SustainableCol1\", \"CbusMetroParks\", \"ColumbusDP\", \"COTABus\", \"Indy_CIO\", \n",
    "           \"SustainIndy\", \"IndyParksandRec\", \"IndyDPW\", \"IndyGoBus\", \"IndyDMD\", \"Indy_CIO\", \"IndyDBNS\"] \n",
    "\n",
    "                        \n",
    "\n",
    "final_results = result[~result['user_ID'].isin(to_keep) == False] # the code above got all mentions & replies\n",
    "len(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhiladelphiaGov.JSON\n",
      "GreenworksPhila.JSON\n",
      "PhillyOTIS.JSON\n",
      "PhilaParkandRec.JSON\n",
      "PhilaHsgAuthPHA.JSON\n",
      "PHLPlanDevelop.JSON\n",
      "PhilaOEM.JSON\n",
      "SEPTA.JSON\n",
      "HPARD.JSON\n",
      "HoustonHCDD.JSON\n",
      "HoustonPlanning.JSON\n",
      "HoustonOEM.JSON\n",
      "HouPublicWorks.JSON\n",
      "HoustonTX.JSON\n",
      "GreenHoustonTx.JSON\n",
      "METROHouston.JSON\n",
      "HoustonOEM.JSON\n",
      "CityofPhoenixAZ.JSON\n",
      "phxenvironment.JSON\n",
      "StreetsPHX.JSON\n",
      "PhoenixParks.JSON\n",
      "PhoenixParks.JSON\n",
      "PHXPlanandDev.JSON\n",
      "ResilientPHX.JSON\n",
      "TalkingTrashPHX.JSON\n",
      "PhoenixMetroBus.JSON\n",
      "COSAGOV.JSON\n",
      "COSAsustainable.JSON\n",
      "SAParksandRec.JSON\n",
      "SATomorrow2040.JSON\n",
      "SanAntonioOEM.JSON\n",
      "CityOfDallas.JSON\n",
      "DallasClimate.JSON\n",
      "DallasParkRec.JSON\n",
      "DallasPlanUD.JSON\n",
      "DallasOEM.JSON\n",
      "dartmedia.JSON\n",
      "dallaszerowaste.JSON\n",
      "CityofJax.JSON\n",
      "JaxReady.JSON\n",
      "JTAFLA.JSON\n",
      "CityofFortWorth.JSON\n",
      "FortWorthParks.JSON\n",
      "FWOEM.JSON\n",
      "TrinityMetro.JSON\n",
      "TarrantCountyTX.JSON\n",
      "CLTgov.JSON\n",
      "CLTSustainable.JSON\n",
      "CharlotteDOT.JSON\n",
      "HNScharlotte.JSON\n",
      "CharMeckEM.JSON\n",
      "CATSRideTransit.JSON\n",
      "CLTWater.JSON\n",
      "ColumbusGov.JSON\n",
      "SustainableCol1.JSON\n",
      "CbusMetroParks.JSON\n",
      "COTABus.JSON\n",
      "Indy_CIO.JSON\n",
      "SustainIndy.JSON\n",
      "IndyParksandRec.JSON\n",
      "IndyDPW.JSON\n",
      "IndyGoBus.JSON\n",
      "IndyDMD.JSON\n",
      "Indy_CIO.JSON\n",
      "IndyDBNS.JSON\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>user_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>City of Philadelphia</td>\n",
       "      <td>2010-04-13T11:01:49</td>\n",
       "      <td>MILITARY TRAINING EXERCISE TO TAKE PLACE IN GR...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PhiladelphiaGov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>City of Philadelphia</td>\n",
       "      <td>2010-03-12T11:50:39</td>\n",
       "      <td>STATEMENT FROM MAYOR NUTTER FOLLOWING PRESIDEN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PhiladelphiaGov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>City of Philadelphia</td>\n",
       "      <td>2010-02-24T12:58:03</td>\n",
       "      <td>CITY EMPLOYEE SENTENCED FOR THEFT FROM NON-PRO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PhiladelphiaGov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>City of Philadelphia</td>\n",
       "      <td>2010-02-12T13:43:45</td>\n",
       "      <td>@SEPTA has the 65 Bus been detoured up 63rd St...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PhiladelphiaGov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>City of Philadelphia</td>\n",
       "      <td>2010-02-11T15:50:33</td>\n",
       "      <td>Update from Mayor Nutter on the City's storm r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PhiladelphiaGov</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                username                 time  \\\n",
       "1   City of Philadelphia  2010-04-13T11:01:49   \n",
       "7   City of Philadelphia  2010-03-12T11:50:39   \n",
       "9   City of Philadelphia  2010-02-24T12:58:03   \n",
       "15  City of Philadelphia  2010-02-12T13:43:45   \n",
       "16  City of Philadelphia  2010-02-11T15:50:33   \n",
       "\n",
       "                                                tweet  likes  replies  \\\n",
       "1   MILITARY TRAINING EXERCISE TO TAKE PLACE IN GR...      0        0   \n",
       "7   STATEMENT FROM MAYOR NUTTER FOLLOWING PRESIDEN...      0        0   \n",
       "9   CITY EMPLOYEE SENTENCED FOR THEFT FROM NON-PRO...      0        0   \n",
       "15  @SEPTA has the 65 Bus been detoured up 63rd St...      0        0   \n",
       "16  Update from Mayor Nutter on the City's storm r...      0        0   \n",
       "\n",
       "            user_ID  \n",
       "1   PhiladelphiaGov  \n",
       "7   PhiladelphiaGov  \n",
       "9   PhiladelphiaGov  \n",
       "15  PhiladelphiaGov  \n",
       "16  PhiladelphiaGov  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_1 = json_to_df(nonclimate_output)\n",
    "\n",
    "result = pd.concat(dataframe_1)\n",
    "result\n",
    "\n",
    "to_keep = [\"PhiladelphiaGov\", \"GreenworksPhila\", \"PhillyOTIS\", \"PhilaParkandRec\", \"PhilaHsgAuthPHA\", \"PHLPlanDevelop\", \n",
    "           \"PhilaOEM\", \"SEPTA\", \"HPARD\",\"HoustonHCDD\", \"HoustonPlanning\", \"HoustonOEM\", \"HouPublicWorks\", \"HoustonTX\", \n",
    "           \"GreenHoustonTx\", \"METROHouston\", \"HoustonOEM\", \"CityofPhoenixAZ\", \"phxenvironment\" , \"StreetsPHX\", \"PhoenixParks\", \n",
    "           \"PhoenixParks\", \"PHXPlanandDev\", \"ResilientPHX\", \"TalkingTrashPHX\", \"PhoenixMetroBus\", \"COSAGOV\", \"COSAsustainable\",\n",
    "           \"SAParksandRec\", \"SATomorrow2040\", \"SanAntonioOEM\", \"CityOfDallas\", \"DallasClimate\", \"DallasParkRec\", \"DallasPlanUD\", \n",
    "           \"DallasOEM\", \"dartmedia\", \"dallaszerowaste\", \"CityofJax\", \"JaxReady\", \"JTAFLA\", \"CityofFortWorth\", \"FortWorthParks\", \n",
    "           \"FWOEM\", \"TrinityMetro\", \"TarrantCountyTX\", \"CLTgov\", \"CLTSustainable\", \"CharlotteDOT\", \"HNScharlotte\", \"CharMeckEM\", \n",
    "           \"CATSRideTransit\", \"CLTWater\", \"ColumbusGov\", \"SustainableCol1\", \"CbusMetroParks\", \"ColumbusDP\", \"COTABus\", \"Indy_CIO\", \n",
    "           \"SustainIndy\", \"IndyParksandRec\", \"IndyDPW\", \"IndyGoBus\", \"IndyDMD\", \"Indy_CIO\", \"IndyDBNS\"] \n",
    "\n",
    "                        \n",
    "\n",
    "final_results = result[~result['user_ID'].isin(to_keep) == False] # the code above got all mentions & replies\n",
    "final_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv(\"Non-Climate_Final Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Non-Climate_Final Results.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonclimate_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
