{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Twitter Data for Cities that Have Declared a Climate Emergency #\n",
    "\n",
    "This notebook focuses on getting Twitter data (all tweets) from the 10 largest cities (population-wise) that have declared a climate emergency. \n",
    "\n",
    "    -Los Angeles\n",
    "    -Seattle \n",
    "    -Denver\n",
    "    -New York\n",
    "    -Chicago\n",
    "    -San Diego\n",
    "    -San Jose\n",
    "    -Austin\n",
    "    -San Francisco\n",
    "    -Boston\n",
    "\n",
    "This first portion of the notebook is dedicated to printing an output that we'll use for a library called \"Twitterscraper.\" This package uses CL for data collection. We'll load in the data back into this notebook. \n",
    "\n",
    "https://github.com/taspinar/twitterscraper\n",
    "    \n",
    "Once the data from twitterscraper is loaded, for the last portion, we'll then merge all of the cities' data into one large dataset for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import json      # library for working with JSON-formatted text strings\n",
    "import pprint as pp    # library for cleanly printing Python data structures\n",
    "import seaborn as sns\n",
    "import twitterscraper as ts\n",
    "from twitterscraper import query_tweets #library downloaded\n",
    "import os as os\n",
    "\n",
    "import subprocess #this enables us to pass CL code directly from Jupyter Notebooks \n",
    "from subprocess import Popen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Twitterscraper Command ## \n",
    "\n",
    "The code below scrapes Twitter accounts from each city, scrapes *all* of their tweets, and makes one big JSON file. Rather than pasting the command into the CL, this function uses \"subprocess\" (a standard library already with Python) to pass the command directly through Jupyter Notebooks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(json_files):\n",
    "    data_frames = []\n",
    "    \n",
    "    for file in json_files:\n",
    "        print (file)\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        d = {'username': [x['username'] for x in data],\n",
    "        'time': [x['timestamp'] for x in data],\n",
    "        'tweet': [x['text'] for x in data],\n",
    "        'likes': [x['likes'] for x in data],\n",
    "        'replies': [x['replies'] for x in data],\n",
    "        'user_ID' : [x['screen_name'] for x in data]}\n",
    "    \n",
    "        data_frames.append(pd.DataFrame.from_dict(d))\n",
    "    return data_frames\n",
    "\n",
    "def combine_data(data_frames): #this will allow us to merge dataframes \"*\" allows us to pass X dataframes\n",
    "    return pd.concat(data_frames)\n",
    "\n",
    "\n",
    "def buildQuery(accounts):\n",
    "    scraper_query = ''\n",
    "    \n",
    "    #this builds our search query\n",
    "    for index, each_account in enumerate (accounts):\n",
    "        next_index = index + 1 #this is so that we don't have an extra \"OR\" at the end, it \"knows\" the last thing\n",
    "        if next_index > len(accounts) - 1: \n",
    "            scraper_query = scraper_query + \"from:\"+ each_account\n",
    "        else:\n",
    "            scraper_query = scraper_query + \"from:\"+ each_account + \" OR \"\n",
    "            \n",
    "    return scraper_query\n",
    "\n",
    "def launch(command, output):\n",
    "    print (command)\n",
    "    \n",
    "    outputFile = open(output, 'w+')\n",
    "    p = Popen(command, stdout=outputFile, stderr=outputFile, universal_newlines=True)\n",
    "    output, errors = p.communicate()\n",
    "    #p.wait() # Wait for sub process to finish before moving on to make frame \n",
    "    \n",
    "    if errors:\n",
    "        print (errors)\n",
    "    myoutput.close()\n",
    "            \n",
    "def scrape(accounts):\n",
    "    data_files = []\n",
    "    \n",
    "    for user in accounts:\n",
    "        path_to_output_file = user + \".txt\" #we'll get both txt and json, but just ignore txt\n",
    "        path_to_data_file = user + \".JSON\"\n",
    "        data_files.append(path_to_data_file)\n",
    "        \n",
    "        query = 'from: ' + user\n",
    "        command = [\"twitterscraper\", query, \n",
    "                   \"--lang\", \"en\", \"--all\", \"-ow\", \"-p\", \"40\", \"-o\", path_to_data_file]\n",
    "        launch(command, path_to_output_file)\n",
    " \n",
    "    return data_files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I created a list of all the accounts I wish to scrape (I broke it up into 3 \"searches\" because this process is extremely time-consuming). However, using \"scrape()\" you can input all the accounts, it'll just an hour or so to get all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitterscraper', 'from: SeattleOPCD', '--lang', 'en', '-o', 'SeattleOPCD.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: CityofSeattle', '--lang', 'en', '-o', 'CityofSeattle.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: seattledot', '--lang', 'en', '-o', 'seattledot.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: SeattleOSE', '--lang', 'en', '-o', 'SeattleOSE.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: kcmetrobus', '--lang', 'en', '-o', 'kcmetrobus.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: LACity', '--lang', 'en', '-o', 'LACity.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: LADOTofficial', '--lang', 'en', '-o', 'LADOTofficial.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: lacountyparks', '--lang', 'en', '-o', 'lacountyparks.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: HCIDLA', '--lang', 'en', '-o', 'HCIDLA.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: Planning4LA', '--lang', 'en', '-o', 'Planning4LA.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: metrolosangeles', '--lang', 'en', '-o', 'metrolosangeles.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: PortofLA', '--lang', 'en', '-o', 'PortofLA.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: NYC_DOT', '--lang', 'en', '-o', 'NYC_DOT.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: NYCParks', '--lang', 'en', '-o', 'NYCParks.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: NYCHA', '--lang', 'en', '-o', 'NYCHA.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: NYCPlanning', '--lang', 'en', '-o', 'NYCPlanning.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: nycemergencymgt', '--lang', 'en', '-o', 'nycemergencymgt.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n",
      "['twitterscraper', 'from: MTA', '--lang', 'en', '-o', 'MTA.JSON', '--all', '-ow', '-p', '40']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "climate_emergency_accounts = [\"SeattleOPCD\", \"CityofSeattle\", \"seattledot\", \"SeattleOSE\", \"kcmetrobus\", \n",
    "                             \"LACity\", \"LADOTofficial\", \"lacountyparks\", \"HCIDLA\", \"Planning4LA\", \"metrolosangeles\", \"PortofLA\", \n",
    "                             \"NYC_DOT\", \"NYCParks\", \"NYCHA\", \"NYCPlanning\", \"nycemergencymgt\", \"MTA\"]\n",
    "                             \n",
    "climate_emergency_output = scrape(climate_emergency_accounts) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitterscraper', 'from: chicago', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'chicago.JSON']\n",
      "['twitterscraper', 'from: ChicagoDOT', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ChicagoDOT.JSON']\n",
      "['twitterscraper', 'from: ChicagoParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ChicagoParks.JSON']\n",
      "['twitterscraper', 'from: ChicagoDOH', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ChicagoDOH.JSON']\n",
      "['twitterscraper', 'from: ChicagoDPD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ChicagoDPD.JSON']\n",
      "['twitterscraper', 'from: ChicagoOEMC', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ChicagoOEMC.JSON']\n",
      "['twitterscraper', 'from: cta', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'cta.JSON']\n",
      "['twitterscraper', 'from: CityofSanDiego', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityofSanDiego.JSON']\n",
      "['twitterscraper', 'from: sandiegoparks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'sandiegoparks.JSON']\n",
      "['twitterscraper', 'from: SanDiegoPlan', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SanDiegoPlan.JSON']\n",
      "['twitterscraper', 'from: ReadySanDiego', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ReadySanDiego.JSON']\n",
      "['twitterscraper', 'from: sdcountydpw', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'sdcountydpw.JSON']\n",
      "['twitterscraper', 'from: sdmts', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'sdmts.JSON']\n",
      "['twitterscraper', 'from: portofsandiego', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'portofsandiego.JSON']\n"
     ]
    }
   ],
   "source": [
    "climate_emergency_accounts_2 = [\"chicago\", \"ChicagoDOT\", \"ChicagoParks\", \"ChicagoDOH\", \"ChicagoDPD\", \"ChicagoOEMC\", \"cta\", \n",
    "                             \"CityofSanDiego\", \"sandiegoparks\", \"SanDiegoPlan\", \"ReadySanDiego\", \"sdcountydpw\", \"sdmts\", \"portofsandiego\"]\n",
    "\n",
    "\n",
    "climate_emergency_output_2 = scrape(climate_emergency_accounts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitterscraper', 'from: CityofSanJose', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityofSanJose.JSON']\n",
      "['twitterscraper', 'from: SanJoseDOT', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SanJoseDOT.JSON']\n",
      "['twitterscraper', 'from: sjparksandrec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'sjparksandrec.JSON']\n",
      "['twitterscraper', 'from: sjcityhousing', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'sjcityhousing.JSON']\n",
      "['twitterscraper', 'from: buildingsanjose', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'buildingsanjose.JSON']\n",
      "['twitterscraper', 'from: VTA', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'VTA.JSON']\n",
      "['twitterscraper', 'from: austintexasgo', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'austintexasgo.JSON']\n",
      "['twitterscraper', 'from: austinmobility', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'austinmobility.JSON']\n",
      "['twitterscraper', 'from: AustinCityParks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'AustinCityParks.JSON']\n",
      "['twitterscraper', 'from: Hacanet', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'Hacanet.JSON']\n",
      "['twitterscraper', 'from: ImagineAustin', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'ImagineAustin.JSON']\n",
      "['twitterscraper', 'from: AustinHSEM', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'AustinHSEM.JSON']\n",
      "['twitterscraper', 'from: AusPublicHealth', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'AusPublicHealth.JSON']\n",
      "['twitterscraper', 'from: CapMetroATX', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CapMetroATX.JSON']\n",
      "['twitterscraper', 'from: SFEnvironment', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SFEnvironment.JSON']\n",
      "['twitterscraper', 'from: sfmta_muni', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'sfmta_muni.JSON']\n",
      "['twitterscraper', 'from: RecParkSF', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'RecParkSF.JSON']\n",
      "['twitterscraper', 'from: sfplanning', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'sfplanning.JSON']\n",
      "['twitterscraper', 'from: SF_emergency', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SF_emergency.JSON']\n",
      "['twitterscraper', 'from: sfpublicworks', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'sfpublicworks.JSON']\n",
      "['twitterscraper', 'from: SFPort', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SFPort.JSON']\n",
      "['twitterscraper', 'from: CityOfBoston', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'CityOfBoston.JSON']\n",
      "['twitterscraper', 'from: BostonEnviro', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'BostonEnviro.JSON']\n",
      "['twitterscraper', 'from: BostonBTD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'BostonBTD.JSON']\n",
      "['twitterscraper', 'from: BostonParksDept', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'BostonParksDept.JSON']\n",
      "['twitterscraper', 'from: BHA_Boston', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'BHA_Boston.JSON']\n",
      "['twitterscraper', 'from: BostonPlans', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'BostonPlans.JSON']\n",
      "['twitterscraper', 'from: AlertBoston', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'AlertBoston.JSON']\n",
      "['twitterscraper', 'from: HealthyBoston', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'HealthyBoston.JSON']\n",
      "['twitterscraper', 'from: MBTA', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'MBTA.JSON']\n",
      "['twitterscraper', 'from: DenverCityGov', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DenverCityGov.JSON']\n",
      "['twitterscraper', 'from: SustainableDen', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'SustainableDen.JSON']\n",
      "['twitterscraper', 'from: DenverDOTI', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DenverDOTI.JSON']\n",
      "['twitterscraper', 'from: denverparksrec', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'denverparksrec.JSON']\n",
      "['twitterscraper', 'from: DenverCPD', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DenverCPD.JSON']\n",
      "['twitterscraper', 'from: DDPHE', '--lang', 'en', '--all', '-ow', '-p', '40', '-o', 'DDPHE.JSON']\n"
     ]
    }
   ],
   "source": [
    "climate_emergency_accounts_3 = [\"CityofSanJose\", \"SanJoseDOT\", \"sjparksandrec\", \"sjcityhousing\", \"buildingsanjose\", \"VTA\", \n",
    "                             \"austintexasgo\", \"austinmobility\", \"AustinCityParks\", \"Hacanet\", \"ImagineAustin\", \"AustinHSEM\", \"AusPublicHealth\", \"CapMetroATX\", \n",
    "                             \"SFEnvironment\", \"sfmta_muni\", \"RecParkSF\", \"sfplanning\", \"SF_emergency\", \"sfpublicworks\", \"SFPort\", \n",
    "                             \"CityOfBoston\", \"BostonEnviro\", \"BostonBTD\", \"BostonParksDept\", \"BHA_Boston\", \"BostonPlans\", \"AlertBoston\", \"HealthyBoston\", \"MBTA\", \n",
    "                             \"DenverCityGov\", \"SustainableDen\", \"DenverDOTI\", \"denverparksrec\", \"DenverCPD\", \"DDPHE\"] \n",
    "\n",
    "climate_emergency_output_3 = scrape(climate_emergency_accounts_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SeattleOPCD.JSON', 'CityofSeattle.JSON', 'seattledot.JSON', 'SeattleOSE.JSON', 'kcmetrobus.JSON', 'LACity.JSON', 'LADOTofficial.JSON', 'lacountyparks.JSON', 'HCIDLA.JSON', 'Planning4LA.JSON', 'metrolosangeles.JSON', 'PortofLA.JSON', 'NYC_DOT.JSON', 'NYCParks.JSON', 'NYCHA.JSON', 'NYCPlanning.JSON', 'nycemergencymgt.JSON', 'MTA.JSON']\n"
     ]
    }
   ],
   "source": [
    "#ignore the below, my original function didn't return a list with .JSON - and I didn't want to re-run the scraping process. \n",
    "\n",
    "climate_emergency_accounts = [\"SeattleOPCD\", \"CityofSeattle\", \"seattledot\", \"SeattleOSE\", \"kcmetrobus\", \n",
    "                             \"LACity\", \"LADOTofficial\", \"lacountyparks\", \"HCIDLA\", \"Planning4LA\", \"metrolosangeles\", \"PortofLA\", \n",
    "                             \"NYC_DOT\", \"NYCParks\", \"NYCHA\", \"NYCPlanning\", \"nycemergencymgt\", \"MTA\"]\n",
    "\n",
    "climate_emergency_output_1 = []\n",
    "for account in climate_emergency_accounts:\n",
    "    climate_emergency_output_1.append(account + \".JSON\")\n",
    "    \n",
    "print (climate_emergency_output_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting JSONs to DataFrames ##\n",
    "\n",
    "json_to_df() takes the json list output above and converts all the data into a list of dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeattleOPCD.JSON\n",
      "CityofSeattle.JSON\n",
      "seattledot.JSON\n",
      "SeattleOSE.JSON\n",
      "kcmetrobus.JSON\n",
      "LACity.JSON\n",
      "LADOTofficial.JSON\n",
      "lacountyparks.JSON\n",
      "HCIDLA.JSON\n",
      "Planning4LA.JSON\n",
      "metrolosangeles.JSON\n",
      "PortofLA.JSON\n",
      "NYC_DOT.JSON\n",
      "NYCParks.JSON\n",
      "NYCHA.JSON\n",
      "NYCPlanning.JSON\n",
      "nycemergencymgt.JSON\n",
      "MTA.JSON\n",
      "chicago.JSON\n",
      "ChicagoDOT.JSON\n",
      "ChicagoParks.JSON\n",
      "ChicagoDOH.JSON\n",
      "ChicagoDPD.JSON\n",
      "ChicagoOEMC.JSON\n",
      "cta.JSON\n",
      "CityofSanDiego.JSON\n",
      "sandiegoparks.JSON\n",
      "SanDiegoPlan.JSON\n",
      "ReadySanDiego.JSON\n",
      "sdcountydpw.JSON\n",
      "sdmts.JSON\n",
      "portofsandiego.JSON\n",
      "CityofSanJose.JSON\n",
      "SanJoseDOT.JSON\n",
      "sjparksandrec.JSON\n",
      "sjcityhousing.JSON\n",
      "buildingsanjose.JSON\n",
      "VTA.JSON\n",
      "austintexasgo.JSON\n",
      "austinmobility.JSON\n",
      "AustinCityParks.JSON\n",
      "Hacanet.JSON\n",
      "ImagineAustin.JSON\n",
      "AustinHSEM.JSON\n",
      "AusPublicHealth.JSON\n",
      "CapMetroATX.JSON\n",
      "SFEnvironment.JSON\n",
      "sfmta_muni.JSON\n",
      "RecParkSF.JSON\n",
      "sfplanning.JSON\n",
      "SF_emergency.JSON\n",
      "sfpublicworks.JSON\n",
      "SFPort.JSON\n",
      "CityOfBoston.JSON\n",
      "BostonEnviro.JSON\n",
      "BostonBTD.JSON\n",
      "BostonParksDept.JSON\n",
      "BHA_Boston.JSON\n",
      "BostonPlans.JSON\n",
      "AlertBoston.JSON\n",
      "HealthyBoston.JSON\n",
      "MBTA.JSON\n",
      "DenverCityGov.JSON\n",
      "SustainableDen.JSON\n",
      "DenverDOTI.JSON\n",
      "denverparksrec.JSON\n",
      "DenverCPD.JSON\n",
      "DDPHE.JSON\n"
     ]
    }
   ],
   "source": [
    "dataframe_1 = json_to_df(climate_emergency_output_1)\n",
    "\n",
    "dataframe_2 = json_to_df(climate_emergency_output_2)\n",
    "\n",
    "dataframe_3 = json_to_df(climate_emergency_output_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>user_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seattle Office of Planning &amp; Community Develop...</td>\n",
       "      <td>2016-01-08T23:37:18</td>\n",
       "      <td>OPCD staff visited Lake City today to meet wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SeattleOPCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seattle Office of Planning &amp; Community Develop...</td>\n",
       "      <td>2016-01-08T23:37:18</td>\n",
       "      <td>OPCD staff visited Lake City today to meet wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SeattleOPCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seattle Office of Planning &amp; Community Develop...</td>\n",
       "      <td>2017-10-05T18:31:02</td>\n",
       "      <td>Bonus #ThrowbackThursday post: Ticket stub fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SeattleOPCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seattle Office of Planning &amp; Community Develop...</td>\n",
       "      <td>2017-09-29T20:17:27</td>\n",
       "      <td>Here's some photos from yesterday's successful...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SeattleOPCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seattle Office of Planning &amp; Community Develop...</td>\n",
       "      <td>2017-09-15T15:30:05</td>\n",
       "      <td>A startup aims to stop gentrification, with he...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SeattleOPCD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            username                 time  \\\n",
       "0  Seattle Office of Planning & Community Develop...  2016-01-08T23:37:18   \n",
       "1  Seattle Office of Planning & Community Develop...  2016-01-08T23:37:18   \n",
       "3  Seattle Office of Planning & Community Develop...  2017-10-05T18:31:02   \n",
       "4  Seattle Office of Planning & Community Develop...  2017-09-29T20:17:27   \n",
       "5  Seattle Office of Planning & Community Develop...  2017-09-15T15:30:05   \n",
       "\n",
       "                                               tweet  likes  replies  \\\n",
       "0  OPCD staff visited Lake City today to meet wit...      1        0   \n",
       "1  OPCD staff visited Lake City today to meet wit...      1        0   \n",
       "3  Bonus #ThrowbackThursday post: Ticket stub fro...      0        0   \n",
       "4  Here's some photos from yesterday's successful...      1        0   \n",
       "5  A startup aims to stop gentrification, with he...      1        0   \n",
       "\n",
       "       user_ID  \n",
       "0  SeattleOPCD  \n",
       "1  SeattleOPCD  \n",
       "3  SeattleOPCD  \n",
       "4  SeattleOPCD  \n",
       "5  SeattleOPCD  "
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge1 = combine_data(dataframe_1)\n",
    "merge2 = combine_data(dataframe_2)\n",
    "merge3 = combine_data(dataframe_3)\n",
    "\n",
    "frames = [merge1, merge2, merge3]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "result\n",
    "\n",
    "to_keep = [\"SeattleOPCD\", \"CityofSeattle\", \"seattledot\", \"SeattleOSE\", \"kcmetrobus\", \n",
    "            \"LACity\", \"LADOTofficial\", \"lacountyparks\", \"HCIDLA\", \"Planning4LA\", \"metrolosangeles\", \"PortofLA\", \n",
    "            \"NYC_DOT\", \"NYCParks\", \"NYCHA\", \"NYCPlanning\", \"nycemergencymgt\", \"MTA\",\n",
    "            \"CityofSanJose\", \"SanJoseDOT\", \"sjparksandrec\", \"sjcityhousing\", \"buildingsanjose\", \"VTA\", \n",
    "            \"austintexasgo\", \"austinmobility\", \"AustinCityParks\", \"Hacanet\", \"ImagineAustin\", \"AustinHSEM\", \"AusPublicHealth\", \"CapMetroATX\", \n",
    "            \"SFEnvironment\", \"sfmta_muni\", \"RecParkSF\", \"sfplanning\", \"SF_emergency\", \"sfpublicworks\", \"SFPort\", \n",
    "            \"CityOfBoston\", \"BostonEnviro\", \"BostonBTD\", \"BostonParksDept\", \"BHA_Boston\", \"BostonPlans\", \"AlertBoston\", \"HealthyBoston\", \"MBTA\", \n",
    "            \"DenverCityGov\", \"SustainableDen\", \"DenverDOTI\", \"denverparksrec\", \"DenverCPD\", \"DDPHE\", \n",
    "             \"chicago\", \"ChicagoDOT\", \"ChicagoParks\", \"ChicagoDOH\", \"ChicagoDPD\", \"ChicagoOEMC\", \"cta\", \n",
    "            \"CityofSanDiego\", \"sandiegoparks\", \"SanDiegoPlan\", \"ReadySanDiego\", \"sdcountydpw\", \"sdmts\", \"portofsandiego\"]\n",
    "\n",
    "final_results = result[~result['user_ID'].isin(to_keep) == False] # the code above got all mentions & replies\n",
    "final_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv(\"Final Results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
